{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you have an AWS secret and access key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new IAM user in your AWS account\n",
    "- Give it AdministratorAccess, From Attach existing policies directly Tab\n",
    "- Take note of the access key and secret\n",
    "- Edit the file dwh.cfg in the same folder as this notebook and fill\n",
    "<font color='red'>\n",
    "<BR>\n",
    "[AWS]<BR>\n",
    "KEY= YOUR_AWS_KEY<BR>\n",
    "SECRET= YOUR_AWS_SECRET<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dwh.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the AWS User Access Key ID and Secret Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "KEY= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "SECRET= config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Local Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Ranjith-Lenovo:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1788a7bd240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Song data JSON file stored in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://udacity-dend/song_data/A/B/C/*.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DATA = config['S3']['SONG_DATA']\n",
    "\n",
    "song_data = INPUT_DATA + \"/A/B/C/*.json\"\n",
    "song_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the JSON file into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARLTWXK1187FB5A3F8</td>\n",
       "      <td>32.74863</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>-97.32925</td>\n",
       "      <td>King Curtis</td>\n",
       "      <td>326.00771</td>\n",
       "      <td>1</td>\n",
       "      <td>SODREIN12A58A7F2E5</td>\n",
       "      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARIOZCU1187FB3A3DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamlet, NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JOHN COLTRANE</td>\n",
       "      <td>220.44689</td>\n",
       "      <td>1</td>\n",
       "      <td>SOCEMJV12A6D4F7667</td>\n",
       "      <td>Giant Steps (Alternate Version_ Take 5_ Altern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude artist_location  artist_longitude  \\\n",
       "0  ARLTWXK1187FB5A3F8         32.74863  Fort Worth, TX         -97.32925   \n",
       "1  ARIOZCU1187FB3A3DC              NaN      Hamlet, NC               NaN   \n",
       "\n",
       "     artist_name   duration  num_songs             song_id  \\\n",
       "0    King Curtis  326.00771          1  SODREIN12A58A7F2E5   \n",
       "1  JOHN COLTRANE  220.44689          1  SOCEMJV12A6D4F7667   \n",
       "\n",
       "                                               title  year  \n",
       "0      A Whiter Shade Of Pale (Live @ Fillmore West)     0  \n",
       "1  Giant Steps (Alternate Version_ Take 5_ Altern...     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "song_f1 = spark.read.json(song_data)\n",
    "song_f1.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the User log data JSON file stored in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://udacity-dend/log_data/2018/11/*.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DATA = config['S3']['LOG_DATA']\n",
    "\n",
    "log_data = INPUT_DATA + \"/2018/11/*.json\"\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harmonia</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541017e+12</td>\n",
       "      <td>583</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>200</td>\n",
       "      <td>1542241826796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.541017e+12</td>\n",
       "      <td>583</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>200</td>\n",
       "      <td>1542242481796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist       auth firstName gender  itemInSession lastName     length  \\\n",
       "0     Harmonia  Logged In      Ryan      M              0    Smith  655.77751   \n",
       "1  The Prodigy  Logged In      Ryan      M              1    Smith  260.07465   \n",
       "\n",
       "  level                            location method      page  registration  \\\n",
       "0  free  San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong  1.541017e+12   \n",
       "1  free  San Jose-Sunnyvale-Santa Clara, CA    PUT  NextSong  1.541017e+12   \n",
       "\n",
       "   sessionId             song  status             ts  \\\n",
       "0        583    Sehr kosmisch     200  1542241826796   \n",
       "1        583  The Big Gundown     200  1542242481796   \n",
       "\n",
       "                                           userAgent userId  \n",
       "0  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     26  \n",
       "1  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     26  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_f1 = spark.read.json(log_data)\n",
    "log_f1.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the DataWareHouse Configuration details to create a Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DWH_ROLE_ARN</td>\n",
       "      <td>arn:aws:iam::501327643673:role/dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param                                   Value\n",
       "0        DWH_CLUSTER_TYPE                              multi-node\n",
       "1           DWH_NUM_NODES                                       4\n",
       "2           DWH_NODE_TYPE                               dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER                              dwhCluster\n",
       "4                  DWH_DB                                     dwh\n",
       "5             DWH_DB_USER                                 dwhuser\n",
       "6         DWH_DB_PASSWORD                                Passw0rd\n",
       "7                DWH_PORT                                    5439\n",
       "8       DWH_IAM_ROLE_NAME                                 dwhRole\n",
       "9            DWH_ROLE_ARN  arn:aws:iam::501327643673:role/dwhRole"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_ENDPOINT           = config.get(\"DWH\", \"DWH_ENDPOINT\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "DWH_ROLE_ARN           = config.get(\"IAM_ROLE\", \"ARN\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "[\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\", \"DWH_ROLE_ARN\"],\n",
    "              \"Value\":\n",
    "[DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME, DWH_ROLE_ARN]\n",
    "             })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clients for EC2, S3, IAM, and RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource(\"ec2\", \n",
    "                     region_name=\"us-east-1\",\n",
    "                     aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET)\n",
    "\n",
    "s3 = boto3.resource(\"s3\",\n",
    "                    region_name=\"us-east-1\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)\n",
    "\n",
    "iam = boto3.client(\"iam\",\n",
    "                    region_name=\"us-east-1\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)\n",
    "\n",
    "redshift = boto3.client(\"redshift\",\n",
    "                          region_name=\"us-east-1\",\n",
    "                          aws_access_key_id=KEY,\n",
    "                          aws_secret_access_key=SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the columns from the songs data dataframe to create dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_f1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create songs DataFrame for creating songs dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- songs table: columns\n",
    "- song_id, title, artist_id, year, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOQFYBD12AB0182188|               Intro|ARAADXM1187FB3ECDB|1999| 67.63057|\n",
      "|SOFIUVJ12A8C13C296|Will You Tell Me ...|AR9OEB71187B9A97C6|2005|397.16526|\n",
      "|SOGDBUF12A8C140FAA|               Intro|AR558FS1187FB45658|2003| 75.67628|\n",
      "|SOBHXUU12A6D4F5F14|National Emblem (...|ARBDJHO1252CCFA6FC|   0|188.73424|\n",
      "|SOIKLJM12A8C136355|           Eso Duele|AR7AE0W1187B98E40E|2003|196.25751|\n",
      "|SOEVPWF12A58A7D254|         Astral eyes|ARCJWLU1187B9ADD36|1997|274.54649|\n",
      "|SODWBIK12AB017F87D|               Aüita|ARSMG8X1187B99CA99|2009| 210.1024|\n",
      "|SOUPIRU12A6D4FA1E1| Der Kleine Dompfaff|ARJIE2Y1187B994AB7|   0|152.92036|\n",
      "|SOHTCZS12A6D4FC402|  The Christmas Song|AROSPS51187B9B481F|1965|197.95546|\n",
      "|SODAUVL12A8C13D184|           Prognosis|ARWB3G61187FB49404|2000|363.85914|\n",
      "|SOYLILV12A8C136650|                 XXX|ARZJDBC1187FB52056|1984|327.00036|\n",
      "|SOTMKDG12A67ADAB35|        Race Of Hate|AREH0O41187FB4C405|1997|311.90159|\n",
      "|SOMAPYF12A6D4FEC3E|All Day & All Of ...|AR5S9OB1187B9931E3|   0|156.62975|\n",
      "|SOCEMJV12A6D4F7667|Giant Steps (Alte...|ARIOZCU1187FB3A3DC|   0|220.44689|\n",
      "|SORRZGD12A6310DBC3|      Harajuku Girls|ARVBRGZ1187FB4675A|2004|290.55955|\n",
      "|SODREIN12A58A7F2E5|A Whiter Shade Of...|ARLTWXK1187FB5A3F8|   0|326.00771|\n",
      "|SOTDCIR12AB0184574|     I Need A Mother|ARZGTK71187B9AC7F5|2010|158.01424|\n",
      "|SOAPVNX12AB0187625|I Remember Nights...|AR5T40Y1187B9996C6|1998| 249.3122|\n",
      "|SONSKXP12A8C13A2C9|         Native Soul|AR0IAWL1187B9A96D0|2003|197.19791|\n",
      "|SOWQTQZ12A58A7B63E|Streets On Fire (...|ARPFHN61187FB575F6|   0|279.97995|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table = song_f1.select([\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]).dropDuplicates()\n",
    "songs_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artists DataFrame for creating artists dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- artists table: columns\n",
    "- artist_id, name, location, lattitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------------------+---------------+----------------+\n",
      "|         artist_id|     artist_name|   artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+----------------+------------------+---------------+----------------+\n",
      "|AR0IAWL1187B9A96D0|    Danilo Perez|            Panama|         8.4177|       -80.11278|\n",
      "|ARWB3G61187FB49404|     Steve Morse|    Hamilton, Ohio|           null|            null|\n",
      "|ARJIE2Y1187B994AB7|     Line Renaud|                  |           null|            null|\n",
      "|ARVBRGZ1187FB4675A|    Gwen Stefani|                  |           null|            null|\n",
      "|ARCKOJF1241B9C75B4|    Eddie Sierra|                  |           null|            null|\n",
      "|ARLTWXK1187FB5A3F8|     King Curtis|    Fort Worth, TX|       32.74863|       -97.32925|\n",
      "|AR5S9OB1187B9931E3|     Bullet Boys|   Los Angeles, CA|       34.05349|      -118.24532|\n",
      "|ARPFHN61187FB575F6|     Lupe Fiasco|       Chicago, IL|       41.88415|       -87.63241|\n",
      "|ARZGTK71187B9AC7F5|            Eels|   California, USA|           null|            null|\n",
      "|ARAADXM1187FB3ECDB|Styles Of Beyond|Woodland Hills, CA|        34.1688|      -118.61092|\n",
      "+------------------+----------------+------------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table = song_f1.select([\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\"]).dropDuplicates()\n",
    "artists_table.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the columns from the user log data dataframe to create dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of the user log dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_f1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users DataFrame for creating users dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- users - users in the app\n",
    "- user_id, first_name, last_name, gender, level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Wyatt</td>\n",
       "      <td>Scott</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Rosales</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId firstName lastName gender level\n",
       "0     26      Ryan    Smith      M  free\n",
       "1     26      Ryan    Smith      M  free\n",
       "2     26      Ryan    Smith      M  free\n",
       "3      9     Wyatt    Scott      M  free\n",
       "4     12    Austin  Rosales      M  free"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = log_f1.select(['userId', 'firstName', 'lastName', 'gender', 'level'])\n",
    "users.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create time DataFrame for creating time dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time - timestamps of records in songplays broken down into specific units\n",
    "- start_time, hour, day, week, month, year, weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "\n",
    "from pyspark.sql.types import TimestampType, DateType\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1542241826796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1542242481796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1542242741796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1542247071796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542252577796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ts\n",
       "0  1542241826796\n",
       "1  1542242481796\n",
       "2  1542242741796\n",
       "3  1542247071796\n",
       "4  1542252577796"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = log_f1.select(['ts'])\n",
    "time.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_datetime(ts):\n",
    "    return datetime.fromtimestamp(ts/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timestamp = udf(lambda x: datetime.fromtimestamp(x/1000.0),TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time.withColumn(\"timestamp\", get_timestamp(time.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datetime = udf(lambda x: datetime.fromtimestamp(x/1000.0), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time.withColumn(\"datetime\", get_datetime(time.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+\n",
      "|           ts|           timestamp|  datetime|\n",
      "+-------------+--------------------+----------+\n",
      "|1542241826796|2018-11-14 19:30:...|2018-11-14|\n",
      "|1542242481796|2018-11-14 19:41:...|2018-11-14|\n",
      "|1542242741796|2018-11-14 19:45:...|2018-11-14|\n",
      "|1542247071796|2018-11-14 20:57:...|2018-11-14|\n",
      "|1542252577796|2018-11-14 22:29:...|2018-11-14|\n",
      "+-------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = time.select(col('ts').alias('start_time'),\n",
    "                        f.hour(time.timestamp).alias('hour'),\n",
    "                        f.dayofweek(time.datetime).alias('day'),\n",
    "                        f.weekofyear(time.datetime).alias('week'),\n",
    "                        f.month(time.datetime).alias('month'), \n",
    "                        f.year(time.datetime).alias('year'),\n",
    "                        date_format(time.datetime, 'E').alias('weekday')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1542285613796</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1542290569796</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1542292733796</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1542810192796</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Wed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542833047796</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>Wed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_time  hour  day  week  month  year weekday\n",
       "0  1542285613796     7    5    46     11  2018     Thu\n",
       "1  1542290569796     9    5    46     11  2018     Thu\n",
       "2  1542292733796     9    5    46     11  2018     Thu\n",
       "3  1542810192796     9    4    47     11  2018     Wed\n",
       "4  1542833047796    15    4    47     11  2018     Wed"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8023"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create songs DataFrame for creating songplays fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- songs - songs in music database\n",
    "- song_id, title, artist_id, year, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- songplays - records in log data associated with song plays i.e. records with page NextSong\n",
    "- songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays = log_f1.select([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", KEY)\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", SECRET)\n",
    "\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a S3 Bucket for a given region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bucket to store the dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = create_bucket(\"deshagvrk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the songs DataFrame (table) in Parquet format in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "songs.write.parquet(\"s3a://deshgvrk1/parquet/songsparquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
